# Tasks-for-Data-Science-Interns-task-4-

# **Boston Housing Price Prediction**

This project implements **Linear Regression**, **Random Forest**, and **XGBoost** models from scratch (without using `sklearn.linear_model`, `RandomForestRegressor`, or `XGBoost`) to predict house prices using the Boston Housing dataset. The models are evaluated using **RMSE (Root Mean Squared Error)** and **R² Score**.


> Load Boston Housing dataset and normalize features.

> Implement Linear Regression from scratch using gradient descent.

> Build Decision Trees from scratch for Random Forest and XGBoost.

> Combine multiple trees to create:

> Random Forest (bagging of trees).

> XGBoost (boosting with residual fitting).

> Train all models on training data.

> Evaluate models using RMSE and R² metrics.
      
> Visualize feature importance from models.

** Observations / Results**

> Linear Regression is simple and fast, but less accurate.

> Random Forest improves accuracy by combining trees.

> XGBoost gives the best performance, because it focuses on learning from previous mistakes.

**How to Run the Code**
> Upload the boston.csv file in your environment.

Run each script one-by-one:

> linear_regression.py

> random_forest.py

> xgboost.py

Check printed RMSE and R² for performance comparison.
